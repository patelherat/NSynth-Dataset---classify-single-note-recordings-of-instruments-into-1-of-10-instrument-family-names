{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Project2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHXcABTFSXPU"
      },
      "source": [
        "!pip install tensorflow.io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWqZEDTmSCaB"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_io as tfio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "datasets = tfds.load(\"nsynth\", data_dir=\"data\", try_gcs=True)\n",
        "train_dataset, test_dataset, valid_dataset = datasets[\"train\"], datasets[\"test\"], datasets[\"valid\"]\n",
        "\n",
        "# filters out the synth-lead class\n",
        "def filter_fn(x):\n",
        "    if x[\"instrument\"][\"family\"]==9:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "# downsamples the data and moves the 10th class to 9th\n",
        "def preProcessing(inputs):\n",
        "  x = np.array([9], dtype=np.int64)\n",
        "  inputs[\"audio\"] = tf.expand_dims(\n",
        "                     tfio.audio.resample(inputs[\"audio\"] , 16000, 8000)\n",
        "                     , 1)\n",
        "  inputs[\"instrument\"][\"family\"] = tf.where(inputs[\"instrument\"][\"family\"]==10, x, inputs[\"instrument\"][\"family\"])\n",
        "  return (inputs[\"audio\"], inputs[\"instrument\"][\"family\"])\n",
        "\n",
        "def processDataset(dataset):\n",
        "  dataset = dataset.filter(filter_fn)\n",
        "  dataset = dataset.shuffle(1024)     # shuffles data of buffer-size 1024\n",
        "  dataset = dataset.map(preProcessing)\n",
        "  dataset = dataset.batch(50, drop_remainder=True)    # batch-size 50\n",
        "  return dataset\n",
        "\n",
        "# Learning curve\n",
        "def print_accuracy(history):\n",
        "  plt.plot(history.history['accuracy'], label='accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.ylim([0, 1])\n",
        "  plt.legend(loc='lower right')\n",
        "  pltPath = path + '/LSTM_accuracy.png'\n",
        "  plt.savefig(pltPath, bbox_inches='tight')\n",
        "  plt.show()\n",
        "\n",
        "# train_dataset = train_dataset.filter(filter_fn)\n",
        "train_dataset = processDataset(train_dataset)\n",
        "valid_dataset = processDataset(valid_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMaeEuStSjxH",
        "outputId": "53db5eca-9ed7-439f-cfff-85045db9b678"
      },
      "source": [
        "# Model 2 (CNN-LSTM)\n",
        "def createLSTMMOdel():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv1D(32, 3, activation=\"relu\", input_shape=(32000, 1), padding='same'))\n",
        "  model.add(tf.keras.layers.MaxPooling1D(2))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv1D(64, 3, activation=\"relu\", padding='same'))\n",
        "  model.add(tf.keras.layers.MaxPooling1D(2))\n",
        "  model.add(tf.keras.layers.Dropout(0.4))\n",
        "  \n",
        "  model.add(tf.keras.layers.LSTM(32, return_sequences=True))\n",
        "  \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  \n",
        "  model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0003),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "LSTM_model = createLSTMModel()\n",
        "print(LSTM_model.summary())\n",
        "LSTM_history = LSTM_model.fit(train_dataset, epochs=10, validation_data=valid_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_2 (Conv1D)            (None, 32000, 32)         128       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 16000, 32)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16000, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 16000, 64)         6208      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 8000, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8000, 64)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 8000, 32)          12416     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256000)            0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                16384064  \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 11)                715       \n",
            "=================================================================\n",
            "Total params: 16,403,531\n",
            "Trainable params: 16,403,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "5674/5674 [==============================] - 1630s 286ms/step - loss: 1.4295 - accuracy: 0.4744 - val_loss: 1.6190 - val_accuracy: 0.5215\n",
            "Epoch 2/10\n",
            "5674/5674 [==============================] - 1635s 288ms/step - loss: 0.9500 - accuracy: 0.6517 - val_loss: 1.9426 - val_accuracy: 0.5449\n",
            "Epoch 3/10\n",
            "5674/5674 [==============================] - 1636s 288ms/step - loss: 0.7688 - accuracy: 0.7185 - val_loss: 2.0506 - val_accuracy: 0.5575\n",
            "Epoch 4/10\n",
            "5674/5674 [==============================] - 1634s 287ms/step - loss: 0.6511 - accuracy: 0.7608 - val_loss: 2.4698 - val_accuracy: 0.5670\n",
            "Epoch 5/10\n",
            "5674/5674 [==============================] - 1628s 286ms/step - loss: 0.5581 - accuracy: 0.7963 - val_loss: 2.6389 - val_accuracy: 0.5901\n",
            "Epoch 6/10\n",
            "5674/5674 [==============================] - 1625s 286ms/step - loss: 0.4910 - accuracy: 0.8206 - val_loss: 2.8965 - val_accuracy: 0.5778\n",
            "Epoch 7/10\n",
            "5674/5674 [==============================] - 1628s 286ms/step - loss: 0.4334 - accuracy: 0.8412 - val_loss: 3.0790 - val_accuracy: 0.5874\n",
            "Epoch 8/10\n",
            "5674/5674 [==============================] - 1621s 285ms/step - loss: 0.3869 - accuracy: 0.8587 - val_loss: 2.9878 - val_accuracy: 0.6016\n",
            "Epoch 9/10\n",
            "5674/5674 [==============================] - 1622s 285ms/step - loss: 0.3505 - accuracy: 0.8730 - val_loss: 3.5830 - val_accuracy: 0.6021\n",
            "Epoch 10/10\n",
            "5674/5674 [==============================] - 1625s 286ms/step - loss: 0.3216 - accuracy: 0.8831 - val_loss: 3.8397 - val_accuracy: 0.5994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGpDV_izWh7A"
      },
      "source": [
        "# Model 1 (CNN)\n",
        "def createCNNModel():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(tf.keras.layers.Conv1D(32, 3, activation=\"relu\", input_shape=(32000, 1), padding='same'))\n",
        "  model.add(tf.keras.layers.MaxPooling1D(2))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv1D(64, 3, activation=\"relu\", padding='same'))\n",
        "  model.add(tf.keras.layers.MaxPooling1D(2))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(11, activation=\"softmax\"))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                metrics=[\"accuracy\"])\n",
        "  \n",
        "CNN_Model = createCNNModel()\n",
        "\n",
        "CNN_history = CNN_Model.fit(train_dataset, epochs=10, validation_data=valid_dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFsVPIrUlqo4"
      },
      "source": [
        "# Processing the testing dataset\n",
        "test_dataset = test_dataset.filter(filter_fn)\n",
        "test_dataset = test_dataset.map(preProcessing)\n",
        "test_dataset = test_dataset.batch(1, drop_remainder=True)\n",
        "\n",
        "# separating the data and labels from the test dataset\n",
        "def mapping(x):\n",
        "  return list(map(lambda y:y[0], x))\n",
        "X_test = list(map(lambda x:mapping(x[0].numpy()[0]), test_dataset))\n",
        "Y_test = list(map(lambda x:x[1][0].numpy()[0], test_dataset))\n",
        "\n",
        "def predictFromModel(model):\n",
        "  predictions = LSTM_model.predict(test_dataset, verbose=2)\n",
        "  Y_pred = np.argmax(LSTM_predictions, axis=-1)\n",
        "  return predictions, Y_pred\n",
        "\n",
        "CNN_predictions, CNN_Y_pred = predictFromModel(CNN_Model)\n",
        "LSTM_predictions, LSTM_Y_pred = predictFromModel(LSTM_Model)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHmtnjsEz4vO",
        "outputId": "7748cfb5-c899-4069-ad2f-7833123e324a"
      },
      "source": [
        "test_loss, test_acc = LSTM_model.evaluate(test_dataset, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4096/4096 - 282s - loss: 4.1661 - accuracy: 0.6118\n",
            "0.61181640625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z68cqltyXVUZ"
      },
      "source": [
        "test_loss, test_acc = CNN_model.evaluate(test_dataset, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OruP2N2xqWIq"
      },
      "source": [
        "\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Confusion matrix\n",
        "def plotConfusionMatrix(Y_test, Y_pred, path, model_Name):\n",
        "  confusion_matrix = tf.math.confusion_matrix(Y_test, Y_pred, 10) .numpy()\n",
        "  print(confusion_matrix)\n",
        "  df_cm = pd.DataFrame(confusion_matrix, index = [i for i in \"ABCDEFGHIJ\"],\n",
        "                  columns = [i for i in \"ABCDEFGHIJ\"])\n",
        "  plt.figure(figsize = (12,7))\n",
        "  sn.heatmap(df_cm, annot=True, cmap=\"YlGnBu\")\n",
        "  plt.ylabel('True Values')\n",
        "  plt.xlabel('Predicted Values')\n",
        "  plt.savefig(path+\"/ConfusionMatrix_\"+model_Name+\".png\")\n",
        "  plt.show()\n",
        "\n",
        "plotConfusionMatrix(Y_test,LSTM_Y_pred, LSTM_path, \"LSTM\")\n",
        "plotConfusionMatrix(Y_test,CNN_Y_pred, CNN_path, \"CNN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pS4S7YuYVxu"
      },
      "source": [
        "# saving model to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "LSTM_path = F\"/content/gdrive/My Drive/LSTM\" \n",
        "LSTM_Model.save(LSTM_path)\n",
        "print('Saved trained model at %s ' % path)\n",
        "\n",
        "CNN_path = F\"/content/gdrive/My Drive/CNN\" \n",
        "CNN_Model.save(CNN_path)\n",
        "print('Saved trained model at %s ' % path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0JPFmAnrv8q"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "instrument_families = {0:\t\"bass\", 1\t:\"brass\", 2:'flute', 3:\"guitar\",4:\"keyboard\",5:\"mallet\",6:\"organ\",7:\"reed\",8:\"string\",\n",
        "  9:\"vocal\"}\n",
        "\n",
        "# Visualizations for correct class probabilities and frequency(histogram) of correct classifications and mis-classifications\n",
        "def plotCorrectClassProbabilitiesAndHistograms(predictions, path, modelName):\n",
        "  highProbabilityRows={0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
        "  highProbabilities={0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
        "  i=0\n",
        "  #Find the audio rows in the dataset that are correctly classified with highest probabilities\n",
        "  for r in test_dataset:\n",
        "    actual = r[1]\n",
        "\n",
        "    for j in range(0, len(predictions[i])-1):\n",
        "      current = highProbabilities[j]\n",
        "      if predictions[i][j] > current:\n",
        "        highProbabilities[j] = predictions[i][j]\n",
        "        highProbabilityRows[j] = i\n",
        "\n",
        "    i = i+1\n",
        "\n",
        "  # Plotting the correct Class probabilities\n",
        "  i=0\n",
        "  \n",
        "  rows = list(highProbabilityRows.values());\n",
        "  for r in test_dataset:\n",
        "    if i in rows:\n",
        "      class_index = rows.index(i)\n",
        "      class_name = instrument_families[class_index]\n",
        "      signal =r[0][0]\n",
        "      plt.figure(1)\n",
        "      plt.clf()\n",
        "      plt.title(\"Signal Wave - \"+class_name + \", probability - \"+ str(predictions[i][class_index]))\n",
        "      plt.plot(signal)\n",
        "      plt.savefig(path+\"/Visualizations/correctClassProbabilities/\"+class_name)\n",
        "      plt.show()\n",
        "    i = i+1\n",
        "\n",
        "    # Plot the histograms for the correcctly classified ones\n",
        "  plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})\n",
        "\n",
        "  # Plot Histogram on x\n",
        "  for i in range(0,10):\n",
        "    row_index = highProbabilityRows[i]\n",
        "    class_name = instrument_families[i]\n",
        "    plt.clf()\n",
        "    plt.hist(X_test[row_index][:-16000], bins=100)\n",
        "    plt.gca().set(title=class_name+': Correct Class Frequency Histogram', ylabel='Frequency');\n",
        "    plt.savefig(path+\"/Visualizations/correctClassHistograms/Histograms_\"+class_name+\"_\"+ modelName)\n",
        "    plt.show()\n",
        "\n",
        "plotCorrectClassProbabilitiesAndHistograms(CNN_predictions,CNN_path, \"CNN\")\n",
        "plotCorrectClassProbabilitiesAndHistograms(LSTM_predictions,LSTM_path, \"LSTM\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5RE4rF0-Jxc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wave\n",
        "import sys\n",
        "i=0\n",
        "\n",
        "copy_predictions = np.copy(predictions)\n",
        "\n",
        "neardecisionBoundaries_probab = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
        "neardecisionBoundaries_indices = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
        "decisionBoundaries_diff = {0:1,1:1,2:1,3:1,4:1,5:1,6:1,7:1,8:1,9:1}\n",
        "max_probabilities = []\n",
        "nextMax_prob = []\n",
        "nextMax_Class = []\n",
        "\n",
        "# Instruments near decision boundary - visualization\n",
        "def plotInstrumentsNearDecisionBoundaries(predictions, path, ModelName):\n",
        "  i =0\n",
        "  for pred in copy_predictions:\n",
        "    max = np.argmax(pred)\n",
        "    max_prob = pred[max]\n",
        "    max_probabilities.append(max_prob)\n",
        "    pred = np.delete(pred, max)\n",
        "    nextMax_probab = np.max(pred)\n",
        "    nextMaxIndex = np.where(predictions[i]==nextMax_probab)\n",
        "    nextMax_prob.append(nextMax_probab)\n",
        "    nextMax_Class.append(nextMaxIndex[0][0])\n",
        "    i = i+1\n",
        "\n",
        "  for i in range(0,len(predictions)):\n",
        "    diff = max_probabilities[i] - nextMax_prob[i]\n",
        "    if diff < decisionBoundaries_diff[nextMax_Class[i]]:\n",
        "      decisionBoundaries_diff[nextMax_Class[i]] = diff\n",
        "      neardecisionBoundaries_probab[nextMax_Class[i]] = nextMax_prob[i]\n",
        "      neardecisionBoundaries_indices[nextMax_Class[i]] = i\n",
        "\n",
        "  rows = list(neardecisionBoundaries_indices.values())\n",
        "  i=1\n",
        "  for r in test_dataset:\n",
        "    if i in rows:\n",
        "      class_index = rows.index(i)\n",
        "      class_name = instrument_families[class_index]\n",
        "      decisionClass = np.argmax(predictions[i])\n",
        "      decisionProbability = predictions[i][decisionClass]\n",
        "      decisionClass_name = instrument_families[decisionClass]\n",
        "      signal =r[0][0]\n",
        "      plt.figure(1)\n",
        "      plt.clf()\n",
        "      plt.suptitle(\"Correct Class: \"+class_name + \", probability = \"+ str(predictions[i][class_index]))\n",
        "      plt.title('Near by: '+ decisionClass_name+ \", probabilitty = \"+str(decisionProbability) )\n",
        "      plt.plot(signal)\n",
        "      plt.savefig(path+\"/Visualizations/nearDecisionClassProbabilities/\"+class_name)\n",
        "      plt.show()\n",
        "    i = i+1\n",
        "\n",
        "  plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})  \n",
        "  # Plot Histogram for misclassified ones\n",
        "  for i in range(0,10):\n",
        "    row_index = neardecisionBoundaries_indices[i]\n",
        "    class_name = instrument_families[i]\n",
        "    plt.clf()\n",
        "    plt.hist(X_test[row_index][:-16000], bins=100)\n",
        "    plt.gca().set(title='Histogram: '+class_name+' misclassified as '+ instrument_families[Y_pred[row_index]], ylabel='Frequency');\n",
        "    plt.savefig(path+\"/Visualizations/missClassificationHistograms/Histogram_MisClassified\"+class_name+\"_\"+ModelName)\n",
        "    plt.show()\n",
        "\n",
        "plotInstrumentsNearDecisionBoundaries(CNN_predictions,CNN_path, \"CNN\")\n",
        "plotInstrumentsNearDecisionBoundaries(LSTM_predictions,LSTM_path, \"LSTM\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}